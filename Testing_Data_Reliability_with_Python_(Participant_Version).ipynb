{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbSiEOBqntq/YzNy1TTtky",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kayley-smiley/Python-Training/blob/main/Testing_Data_Reliability_with_Python_(Participant_Version).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing Data Reliability with Python**\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "\n",
        "This portion of the workshop will introduce you to coding in Python and teach you how to use Python to test data reliability.\n",
        "\n",
        "Specifically, we'll cover:\n",
        "\n",
        "* data types and structures\n",
        "* variables\n",
        "* functions\n",
        "* the pandas library\n",
        "* importing a data set\n",
        "* testing data completeness\n",
        "* testing data accuracy\n",
        "\n",
        "\n",
        "### **What is Python?**\n",
        "\n",
        "* Python is a popular programming language in the data science and machine learning communities.\n",
        "* Python can handle large amounts of data and perform complex analyses.\n",
        "* It is considered one of the more beginner-friendly programming languages.\n",
        "* Python is \"open source\", which means that its source code is made available for use and modification.\n",
        "  * Using Python is free!\n",
        "* It has a large community of developers, which means it's relatively easy to find tutorials and get answers to questions.\n",
        "* Python's capabilities can be extended even further with its extensive collection of libraries, which provide pre-written code.\n",
        "\n",
        "### **Python vs. Excel**\n",
        "* Excel is a user-friendly tool.\n",
        "  * Python has a steeper learning curve.\n",
        "* Excel is sufficient for simple analyses.\n",
        "  * Python can be used for more complex analyses.\n",
        "  * Python can easily handle large amounts of data.\n",
        "\n",
        "### **Google Colab**\n",
        "We will use Google Colab to execute the code for this training because it doesn't require any installation or setup before getting started. Google Colab executes code on Google's cloud servers, instead of your own computer, which means that the power of your computer doesn't impact how fast the code runs. However, there is no data privacy, so it is highly recommended that you **do not** use Google Colab to analyze a data set containing confidential information.\n",
        "\n",
        "\n",
        "### **Getting Started**\n",
        "\n",
        "To analyze data with Python, we will use what's called a \"notebook.\" Notebooks contain a mixture of code and text blocks (or sections), which make it fairly easy to present your work in an organized way, reproduce your work on other data sets, and share your work with others. You can add a block of code or text in two ways: by clicking + Code or + Text in the bar above or by hovering your mouse over the bottom of a current block and then clicking + Code or + Text. You can also move blocks by clicking the ↑ or ↓ buttons that appear when you select a cell. Lastly, if you want to create a new notebook, you can do so by clicking File → New Notebook in the bar above.\n",
        "\n",
        "\n",
        "\n",
        "### **Running Code**\n",
        "\n",
        "When using Python, we can execute or run our code as soon as we write it, which makes it easy to test out ideas. To execute a code block, click the \"play\" button located on the left side of the code block. The output for the code will be displayed below the block."
      ],
      "metadata": {
        "id": "LaOEidnve-Rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1 + 1"
      ],
      "metadata": {
        "id": "Sz2DC-GjP9Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "10 - 2"
      ],
      "metadata": {
        "id": "RqGRRDOTpplQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The table below provides the symbols for some common operations.\n",
        "\n",
        "\n",
        "| Symbol | Operation |\n",
        "| --------- |: ----- |\n",
        "| `+` | Addition |\n",
        "| `-` | Subtraction |\n",
        "| `*` | Multiplication |\n",
        "| `/` | Division |\n",
        "| `**` | Exponentiation |"
      ],
      "metadata": {
        "id": "qzH7OxX8CsMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practice:** Calculate $2^3$ in the code block below."
      ],
      "metadata": {
        "id": "8nuh-e9qGpF9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PTNfp-qqGvqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can type multiple lines of code in the same code block, but output will only display for the last line of code. If you want to print multiple outputs, you can either use separate code blocks or you can use the built-in `print()` function."
      ],
      "metadata": {
        "id": "5WYzq7S6KNBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#only the output for the last line prints\n",
        "2**3\n",
        "5+10"
      ],
      "metadata": {
        "id": "3LBwC_A2XCZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing both outputs\n",
        "print(2**3)\n",
        "print(5+10)"
      ],
      "metadata": {
        "id": "VT-3JEDSXInD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is common practice to use separate code blocks for separate topics."
      ],
      "metadata": {
        "id": "BGLvI62j02lP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Comments**\n",
        "\n",
        "Comments are short notes that you can place in code blocks. They are part of the code, but Python ignores them when the code is run. They are intended to provide clarity for people reading the code or prevent execution when testing code.\n",
        "\n",
        "Comments start with the `#` symbol and everything typed to the right of the `#` symbol will be ignored. You can also distinguish a comment from other code because the text is green.\n"
      ],
      "metadata": {
        "id": "yxOQT9KooK0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is a comment"
      ],
      "metadata": {
        "id": "-7VboMyVZ2pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code below, Python adds `5 + 2` and ignores everything to the right of `#`.\n",
        "\n"
      ],
      "metadata": {
        "id": "MeeRM6vYDLUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "5 + 2 #adding 5 + 2"
      ],
      "metadata": {
        "id": "j5r9NtBRaCqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the code below will run because it's on a new line\n",
        "5 + 8"
      ],
      "metadata": {
        "id": "tpDY8yChOJcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we can also create comments that\n",
        "#are multiple lines"
      ],
      "metadata": {
        "id": "FDJRLXFDOOnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Variables**\n",
        "\n",
        "Variables are essentially containers for storing data. You can also think of them as names that you assign to objects. Variables make it easy to store and reference data in our code.\n",
        "\n",
        "To create a variable, we use the `=` symbol.\n"
      ],
      "metadata": {
        "id": "wr-6XwkSoHL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define a variable named \"x\" as 3\n",
        "x = 3"
      ],
      "metadata": {
        "id": "1wcOFw24GuRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After you've defined a variable, you can see what it equals by typing the variable name or using the `print()` function."
      ],
      "metadata": {
        "id": "wnCitZzEG-jU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "BnlQFrRFG-Cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "id": "zGw-f_iKXUzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several rules when it comes to naming variables:\n",
        "\n",
        "\n",
        "* A variable name **cannot** contain spaces.\n",
        "* The first character in the name must be either a letter or an underscore.\n",
        "  * After the first character, you can use numbers too.\n",
        "*  Uppercase and lowercase letters are distinct.\n",
        "  * `a` and `A` are different variables.\n",
        "* A variable name **cannot** be one of Python's key words, such as `for`, `and`, `or`, `else`, and `in`.\n",
        "* It is recommended that you choose names that are somewhat informative and short.\n",
        "\n",
        "In Colab, clicking on the $\\{x\\}$ symbol to the left will provide a list of variables currently in use.\n",
        "\n",
        "It is important to note that you can save over existing variables! We defined `x` as 3 earlier, but if we run the code below, `x` is now 10.\n",
        "\n"
      ],
      "metadata": {
        "id": "nnbEqanEHrpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = 10\n",
        "x"
      ],
      "metadata": {
        "id": "5F0hq0xKSG4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practice**: Create two variables, `x` and `y`, equal to 5 and 10, respectfully. Then, create a new variable `z` that equals the sum of `x` and `y`, and print the value of `z`."
      ],
      "metadata": {
        "id": "GUiuN2R59c-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E6afv-3c9FYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Types**\n",
        "\n",
        "Variables can store different types of data, which have unique purposes. The table below contains some frequently used data types. There are more data types, such as complex numbers or sets, but we won't discuss these during this workshop.\n",
        "\n",
        "| Type | Description | Example |\n",
        "| :--------- |:----- |:----|\n",
        "| str | text/characters | `'hello'` |\n",
        "| int | integer/whole number | `1` |\n",
        "| float | decimals | `1.2` |\n",
        "| bool | logical value | `True`, `False` |\n",
        "| list | ordered collection of data | `['Colorado', 'Washington', 'Oregon']` |\n",
        "\n",
        "\n",
        "To check the data type for a variable, you can use the built-in `type()` function. Let's check the type of the variable `x`, which was defined in the last practice problem."
      ],
      "metadata": {
        "id": "F67K2bRjQdCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(x)"
      ],
      "metadata": {
        "id": "p7XwJvwflEhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type('hello')"
      ],
      "metadata": {
        "id": "2Ok_JWqaWDWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practice:** In the code block below, find the data type for `31.8`."
      ],
      "metadata": {
        "id": "WuD2WYS3WLcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_MLW8RcvWDKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practice:** In the code block below, find the data type for `[2, 4, 6]`."
      ],
      "metadata": {
        "id": "tJy1Ft22XhKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-s2hrHqcXai3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Booleans**\n",
        "\n",
        "Booleans (bool) represent one of two values: `True` or `False`. In programming, we often want to know if a statement is `True` or `False`."
      ],
      "metadata": {
        "id": "TkZHPc3fduSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "10 > 9"
      ],
      "metadata": {
        "id": "YDc2FK_KZQNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we wanted to check for equality, we can't use `=` since that's how we assign variables. To check for equality, Python uses `==`. The table below provides the symbols for logical operators.\n",
        "\n",
        "| Operator | Symbol |\n",
        "| --------- |: ----- |\n",
        "| equal to | `==`  |\n",
        "| not equal to | `!=` |\n",
        "| greater than | `>` |  \n",
        "| less than | `<`  |\n",
        "| greater than or equal to | `>=` |\n",
        "| less than or equal to | `<=` |"
      ],
      "metadata": {
        "id": "rR8l9XIQZfIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1 == 1"
      ],
      "metadata": {
        "id": "aiPjBfZAZ7KO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is worth knowing that `True` and `False` are equivalent to `1` and `0`. This means that we can add Booleans. That might not seem very useful, but it will come in handy later on."
      ],
      "metadata": {
        "id": "gFIvhMGYJh-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this is equivalent to 1 + 0\n",
        "True + False"
      ],
      "metadata": {
        "id": "3V7KXrAmKA9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practice:** In the code block below, create variables `x` and `y` that equal 1 and 1.0001, respectfully. Then, check to see if `x` is greater than or equal to `y`."
      ],
      "metadata": {
        "id": "E4ThtPnxaIvl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e_dCD8f7bVpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Lists**\n",
        "\n",
        "A list is used to store an ordered collection of data in a single variable. Because lists are ordered, the list `[1, 2, 3]` is not equal to the list `[2, 3, 1]`. Essentially, if two lists have the same elements in different orders, they are not equivalent."
      ],
      "metadata": {
        "id": "armdCeX3BpAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[1, 2, 3] == [2, 3, 1]"
      ],
      "metadata": {
        "id": "K2nd00E0HKsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Functions**\n",
        "\n",
        "We've already used a few functions, like `print()` or `type()`. In general, functions take inputs called arguments and usually produce something in return. The Python documentation provides a complete [list of built-in functions](https://docs.python.org/3/library/functions.html), and the table below includes some of the commonly used functions.\n",
        "\n",
        "| Function | Description |\n",
        "| --------- |: ----- |\n",
        "| `print()` | prints the output |\n",
        "| `sorted()` | sorts a list in ascending order |\n",
        "| `type()` | returns the data type for an object |\n",
        "| `abs()` | returns the absolute value of a number |\n",
        "| `round()` | returns the number rounded to a specified number of decimal places |\n",
        "| `sum()` | returns the sum of items in an object  |\n",
        "| `len()` | returns the length of an object |\n",
        "| `max()` | returns the largest item in an object |\n",
        "| `min()` | returns the smallest item in an object |   "
      ],
      "metadata": {
        "id": "9vmO8hBuOXAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define a list from 1 to 10\n",
        "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ],
      "metadata": {
        "id": "hslY44jD1XH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add the elements in x together\n",
        "sum(x)"
      ],
      "metadata": {
        "id": "h0rzqNRxU5og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practice:** Find the number of elements in `x`."
      ],
      "metadata": {
        "id": "ypL66ZLoA-Jd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7LCJ9OBbU786"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practice:** Find the smallest element in `x`."
      ],
      "metadata": {
        "id": "ckTtdYhdBFcx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gDGZDYK-78by"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Errors**\n",
        "\n",
        "There are three types of errors that can occur when coding in Python: syntax errors, runtime errors, and logical errors. The term **debugging** is often used to describe the process of finding and correcting an error.\n",
        "\n",
        "Syntax refers to the rules that define the structure of a programming language, so **syntax errors** occur when the proper syntax is not followed. An example of a syntax error is leaving out a comma or a bracket.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OFO1mmwmaULY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('hello')"
      ],
      "metadata": {
        "id": "7AmSPHBgFB7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Runtime errors** occur when the syntax is correct, but the program can't run for a different reason, like dividing by zero or trying to access an object that doesn't exist."
      ],
      "metadata": {
        "id": "g4rhq98uFCY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we haven't defined a variable called \"a\"\n",
        "a"
      ],
      "metadata": {
        "id": "jkZADCncFGPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logical errors** are usually the most difficult to fix because there are no error messages. The code runs without any issues, but the result is incorrect due to flawed logic in the code. Examples of logical errors include:\n",
        "\n",
        "  * Using the wrong variables\n",
        "  * Misunderstanding the behavior of a function\n",
        "  * Incorrect use of logical operators\n",
        "\n",
        "Logical errors can often be fixed by checking the results of intermediate steps in the code."
      ],
      "metadata": {
        "id": "bryzJqEQFGj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Libraries**\n",
        "\n",
        "Python has a lot of capabilities on its own, but we can do even more with the use of libraries. Libraries are collections of code and functions that extend the capabilities of Python. Some of the most popular libraries for data analysis are pandas, NumPy, Plotly, SciPy, scikit-learn, and matplotlib.\n",
        "\n",
        "### **The pandas Library**\n",
        "\n",
        "We'll go over the pandas library, which contains a variety of tools for doing things like:\n",
        "* manipulating data\n",
        "* reading and writing data\n",
        "* subsetting data\n",
        "* aggregating or transforming data\n",
        "* merging and joining data sets\n",
        "* time series analysis\n",
        "\n",
        "The pandas library also has a [user guide](https://pandas.pydata.org/docs/user_guide/index.html) that explains how pandas can be used to approach a wide variety of analyses.\n",
        "\n",
        "To use a library in Python, we use an `import` statement. It is recommended to import all libraries at the beginning of the notebook. Although this isn't necessary, it's also common to import libraries under an alias or an alternate shorter name. For example, the pandas library is often imported with an alias of `pd`. This means the library can now be referred to as `pd` instead of `pandas`.\n"
      ],
      "metadata": {
        "id": "NnyOzOYqoAg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Tiu6z-n1nlRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The table below contains some functions from the pandas library; however, this is just scratching the surface. We'll use some of these functions in the following sections to explore data reliability.\n",
        "\n",
        "\n",
        "| Function Name | Use |\n",
        "| --------- |: ----- |\n",
        "| `pd.read_csv()` | imports a csv file as a `DataFrame` |\n",
        "| `DataFrame.info()` | returns a concise summary of a `DataFrame` |\n",
        "| `DataFrame.dtypes` | returns the data types for each column in a `DataFrame` |\n",
        "| `DataFrame.shape` | returns the number of rows and columns in a `DataFrame` |\n",
        "| `DataFrame.columns` | returns the column labels of the `DataFrame` |\n",
        "| `DataFrame.describe()` | returns descriptive statistics for each column in a `DataFrame` |\n",
        "| `DataFrame.sample()` | randomly selects a sample from a `Series` or `DataFrame` |\n",
        "| `DataFrame.isin()` | returns a `DataFrame` of Booleans showing whether each element was contained in the provided set of values |\n",
        "| `DataFrame.isna()` | returns a `DataFrame` filled with Boolean values indicating missing values |\n",
        "| `DataFrame.dropna()` | removes missing values |\n",
        "| `DataFrame.sample()` | randomly selects a sample from a `Series` or `DataFrame` |\n",
        "| `DataFrame.sort_values()` | sorts the values in a `DataFrame` in ascending or descending order based on one or more columns |\n",
        "| `DataFrame.nunique()` | returns a `Series` with the number of distinct elements in each column |\n",
        "| `DataFrame.unique()` | returns unique values in order of appearance |\n",
        "| `DataFrame.value_counts()` | returns a `Series` containing the counts of unique values |\n",
        "| `DataFrame.sum()` | returns the column (or row) sums |\n",
        "| `DataFrame.mean()` | returns the mean of the values |\n",
        "| `DataFrame.std()` | returns the standard deviation of the values |\n",
        "| `DataFrame.groupby()` | groups a `DataFrame` by values in one or more columns |\n",
        "| `pd.to_datetime()` | converts the data type to datetime |\n",
        "| `pd.to_numeric()` | converts the data type to numeric |\n",
        "| `pd.to_string()` | converts the data type to string |\n",
        "| `DataFrame.duplicated()` | returns a Boolean `Series` denoting duplicate rows |\n",
        "| `DataFrame.drop_duplicates()` | returns a `DataFrame` with duplicate rows removed |\n",
        "| `DataFrame.merge()` | merges two `DataFrame` objects |\n",
        "| `DataFrame.to_excel()` | saves a `DataFrame` as an Excel sheet |\n",
        "\n",
        "The pandas [user guide](https://pandas.pydata.org/docs/user_guide/index.html) also contains detailed documentation for all of the functions in the library."
      ],
      "metadata": {
        "id": "mx5b6CBE5PgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Data Structures**\n",
        "\n",
        "pandas has two basic data structures: `Series` and `DataFrame`. A `Series` is a one-dimensional data structure and a `DataFrame` is a two-dimensional data structure. You can think of a `Series` as a single column of data and a `DataFrame` as a dataset that contains many rows and columns."
      ],
      "metadata": {
        "id": "06m0qA4wKUPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Importing Data**\n",
        "\n",
        "pandas contains several functions for importing files, such as the `pd.read_csv()` function, which can be used to import a csv file. This function takes the file path as an argument. Because Google's servers are executing this code (instead of your own computer), the file paths we can specify are limited. If you're not using Google Colab, the file path can be any location on your computer.\n",
        "\n",
        "We'll import the same supplier invoice data set we used earlier in Excel, which is stored as a csv file in [GitHub](https://github.com/kayley-smiley/Python-Training/blob/main/Supplier%20Invoice%20Data%20Final%20for%20Python.csv). Since the data set is stored in GitHub, we'll provide the URL for the file path."
      ],
      "metadata": {
        "id": "LZ7oUyYorHM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define a variable, 'path', that stores the URL for the data\n",
        "#this step is optional and depends on style preference\n",
        "path = 'https://github.com/kayley-smiley/Python-Training/blob/main/Supplier%20Invoice%20Data%20Final%20for%20Python.csv?raw=true'\n",
        "\n",
        "#read in the data and name it 'df'\n",
        "df = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "dFqhDArSyyLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#view the data set\n",
        "df"
      ],
      "metadata": {
        "id": "BEy8ZmywImtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the preview above displays all of the columns from `df`, but not all of the rows. If we want to see more rows when we display an output, we can change the default pandas display settings with the `pd.set_option()` function."
      ],
      "metadata": {
        "id": "rgJNvuo9JdM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#change the minimum number of rows displayed to 20\n",
        "pd.set_option(\"display.min_rows\", 20)"
      ],
      "metadata": {
        "id": "zlf-RC3gJeX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#view df again\n",
        "df"
      ],
      "metadata": {
        "id": "KfhbiY--KRCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The default number of columns can be changed in the same way by using the `display.min_columns` argument."
      ],
      "metadata": {
        "id": "X7Q91x0kKVSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The supplier invoice dataset (`df`) is a `DataFrame` because it contains many rows and columns. Each of its columns are considered a `Series`.\n",
        "\n",
        "When we first import a dataset, it's a good idea to check the size of the dataset and take a look at a couple of rows. To check the size, we can use the `DataFrame.shape` function, which returns the number of rows and columns. To use the function, replace the word `DataFrame` with the name of a `DataFrame` object. In our case, this would be `df`. This rule applies to any pandas function with `DataFrame` in the name."
      ],
      "metadata": {
        "id": "6Y5_qIRIc1wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "t9uLFWPQcRR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our `DataFrame` has 847 rows and 18 columns.\n",
        "\n",
        "To see exactly which columns are included in the `DataFrame`, we can use the `DataFrame.columns` function."
      ],
      "metadata": {
        "id": "tIKtvQxscPAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "L9t3xFKdDf0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To view a couple of rows from the dataset, we can use the `DataFrame.head()` and `DataFrame.tail()` functions. The `DataFrame.head()` function returns rows from the top of the dataset and the `DataFrame.tail()` function returns rows from the bottom of the dataset. Both functions have an optional argument, `n`, to specify the number of rows that will be returned. If you don't specify `n`, the function will default to 5 rows."
      ],
      "metadata": {
        "id": "ZdKEqI6FDgd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#look at the first 5 rows\n",
        "df.head()"
      ],
      "metadata": {
        "id": "rrzBcAeMC3BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#look at the last 8 rows using the optional n argument\n",
        "df.tail(n=8)"
      ],
      "metadata": {
        "id": "Z6fQDSVkDOgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Subsetting a DataFrame**\n",
        "\n",
        "If we only want to look at specific rows or columns of a `DataFrame`, there are several ways that we can create a subset of the data. The general way to subset a `DataFrame` is by specifying the subset inside square brackets, `[]`, after the name of the `DataFrame`.\n",
        "\n",
        "For example, if we want to just look at the `Supplier Name` column from `df`, we can use the following code.\n",
        "\n"
      ],
      "metadata": {
        "id": "6xmBSp0vDu7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Supplier Name']"
      ],
      "metadata": {
        "id": "LPCLoSJ9g7P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to view multiple columns of a `DataFrame`, we can provide a list of column names inside the square brackets."
      ],
      "metadata": {
        "id": "8upSFh9nk7fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['Supplier Name', 'Payment Amount']]"
      ],
      "metadata": {
        "id": "RZ38guCXlBEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also subset a `DataFrame` with a Boolean expression, where the subset includes entries that meet a certain condition.\n",
        "\n",
        "For example, one of the entries in `Supplier Name` is `THE SALVATION ARMY`. We can look at a subset of `df` that only contains rows where the `Supplier Name` is `THE SALVATION ARMY` by placing a Boolean condition inside the brackets."
      ],
      "metadata": {
        "id": "HVDrAw-6GCji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#look at rows in df where the Supplier Name is THE SALVATION ARMY\n",
        "df[df['Supplier Name'] == 'THE SALVATION ARMY']"
      ],
      "metadata": {
        "id": "PsYO-CV8G0Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practice:** Create a subset of `df` that contains rows with an `Invoice Amount` greater than $200,000."
      ],
      "metadata": {
        "id": "UcbIi_iZIxh3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PD7NnjmtIwcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Data Types**\n",
        "\n",
        "For the most part, there is not a big difference between the data types we talked about earlier and data types in pandas. However, we will discuss two additional data types that are specific to pandas: `objects` and `datetime objects`.\n",
        "\n",
        "When you import a `DataFrame`, pandas attempts to guess the data type for each column. Columns with text are marked as `objects` by default. The `object` data type also includes any columns that pandas couldn't easily assign a more specific data type.\n",
        "\n",
        "Let's check the data types for the variables in `df` using the `DataFrame.dtypes` function."
      ],
      "metadata": {
        "id": "6kknSflMg6df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "Qv1Ai08cINCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that most of the columns are `objects`. Since these data types are just guesses by pandas, some may not be the most appropriate choices. For example, `float` is appropriate for `Payment Amount`, but `object` is not the best fit for `Beginning Payment Date`. The pandas `datetime` data type is specifically designed for time series data, which is fitting for `Beginning Payment Date`. It's important to check that data types are correct because they have an impact on functionality. For example, pandas contains certain functions that can only be used on `datetime` objects.\n",
        "\n",
        "To illustrate, if we wanted to create a variable that contains the day of the week for each `Beginning Payment Date`, we can use the `Series.dt.day_name()` function, but notice we get an error if we try to use it on an `object`.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3VizTtFXFulE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Beginning Payment Date'].dt.day_name()"
      ],
      "metadata": {
        "id": "u_HePX7MNVRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the error says, we can only use that function with a `datetime` object, so we first need to change the data type for `Beginning Payment Date`.\n",
        "\n",
        "There are a couple of different ways to change data types in pandas, so we'll just cover the following functions:\n",
        "  * `pd.to_datetime()` changes the data type to `datetime`\n",
        "  * `pd.to_numeric()` changes the data type to `numeric`\n",
        "    * pandas will further label it as `float` or `int` based on the data provided\n",
        "  * `pd.to_string()` changes the data type to `string`\n"
      ],
      "metadata": {
        "id": "BZbeCnRIXGi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.to_datetime(df['Beginning Payment Date'])"
      ],
      "metadata": {
        "id": "i3JC72SEOEDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, this code alone doesn't change the data type for the variable in `df`. To do this, we essentially need to save over the old `Beginning Payment Date` variable with the new version."
      ],
      "metadata": {
        "id": "utAWGVjwOY9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Beginning Payment Date'] = pd.to_datetime(df['Beginning Payment Date'])"
      ],
      "metadata": {
        "id": "MLo_z8ccOkQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's try the `Series.dt.day_name()` function again."
      ],
      "metadata": {
        "id": "fTAjiVC80dBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Beginning Payment Date'].dt.day_name()"
      ],
      "metadata": {
        "id": "7KwOpeSa0nMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's add this new variable to `df` and name it `Payment Day`."
      ],
      "metadata": {
        "id": "3sdFE9X70uO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Payment Day'] = df['Beginning Payment Date'].dt.day_name()\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "y-vFFgRw2N0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practice:** There are a few more date variables in our `DataFrame`: `Invoice Date`, `Accounting Date for Supplier Invoice`, `Bank Cleared Date`, and `Due Date`. Convert the rest of them to the `datetime` type."
      ],
      "metadata": {
        "id": "J2zFYTCj1upC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AiYQR_ap23Fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Data Completeness**\n",
        "\n",
        "Data completeness is the extent to which a dataset contains all the necessary elements and observations for a given purpose or analysis. To evaluate data completeness, we'll focus on missing values and the contents of the data set.\n",
        "\n",
        "**Missing Values**\n",
        "\n",
        "First, we'll identify missing values. When a dataset is loaded, pandas will denote missing values by `NaN`. In many programming languages, including Python, `NaN` is used to represent undefined or unrepresentable values. There is a difference between `NaN` and empty strings, `''`, or strings like `'NA'`. If you have a dataset that includes strings like `'NA'`, `'na'`, or `'N/A'`, these will *not* be identified as missing by pandas.\n",
        "\n",
        "To identify missing values in a `DataFrame`, we can use the `DataFrame.isna()` function. This function will return a Boolean `DataFrame` of the same size indicating if each entry is missing (`True`) or not (`False`).  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6XqUhgnU6HNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna()"
      ],
      "metadata": {
        "id": "9aCHDfu8FgGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This output isn't super helpful on its own for a large `DataFrame`. It would be more useful to have a count of missing values. This is where adding Booleans is really helpful! Since `True` is equivalent to `1`, if we find the sum of Boolean values, this is equivalent to counting the missing values.\n",
        "\n",
        "The `DataFrame.sum()` function will return the column sums for a `DataFrame` by default. If the optional `axis` argument is specified as `1`, then the row sums will be returned."
      ],
      "metadata": {
        "id": "jd31inJGFofV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sum of missing values\n",
        "(df.isna()).sum()"
      ],
      "metadata": {
        "id": "KMY9KdKvE73x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've quantified how many values are missing, it can be helpful to see which rows contain missing values. To do this, we can combine the `DataFrame.isna()` function with the `DataFrame.any()` function. When applied to a `DataFrame`, the `DataFrame.any()` function returns a `Series` indicating if any row (or column) contains a `True` value. By default, the function checks columns, so we need to specify the optional `axis` argument as `1` to look at rows with missing values.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KQTrpjF3A7HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(df.isna()).any(axis = 1)"
      ],
      "metadata": {
        "id": "lG2TbWq4E5zG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we have a `Series` with `True` if the row contains at least one missing value and `False` if the row doesn't contain any missing values. To view the actual rows that contain missing values, we can use the Boolean `Series` to subset `df`."
      ],
      "metadata": {
        "id": "NCJx7Z1FFQ1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[(df.isna()).any(axis = 1)]"
      ],
      "metadata": {
        "id": "JexrqnroFhou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's important to deal with missing values in an appropriate way because they can significantly impact results. For example, any operation involving a `NaN` will return a result of `NaN`.\n",
        "\n",
        "There are a couple of common ways to deal with missing values:\n",
        "* If the missing values are due to an error and you know what should be in their place, the `DataFrame.fillna()` function can be used to replace `NaN` values.\n",
        "  * For example, if you know that missing values should really be `0`, `DataFrame.fillna(0)` will replace each `NaN` with `0`.\n",
        "* Drop any rows from the dataset that contain missing values with the `DataFrame.dropna()` function.\n",
        "  * This can shrink down your data set quickly and can result in a biased data set if values are not missing at random.\n",
        "* Remove missing values from each individual analytic.\n",
        "  * This allows us to use more of the data but can lead to some complications since our analytics are based on different subsets of the data.\n",
        "  * Many Python functions have an optional argument that determines how missing values are handled in calculations.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hhLf5BH_IIDC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking the Data Set Contents**\n",
        "\n",
        "Next, we'll check that the contents of the data set meet our expectations. For example, our supplier invoice data (`df`) should only contain invoices with dates on or after 1/1/2022. Let's double-check that the invoice date range is as expected. One way of doing this is by looking at the minimum and maximum values for the `Invoice Date` column.\n"
      ],
      "metadata": {
        "id": "d3JiV6bv0lLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practice:** Using functions that we discussed earlier, find the minimum and maximum values for `Invoice Date`. Do they meet our expectations?"
      ],
      "metadata": {
        "id": "sAVE6IE-k7l6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CXNDiIdMJlFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way to check the contents of our data set is by looking at the unique values for some of the variables. pandas has a couple of functions that are useful for taking a closer look at variables.\n",
        "\n",
        "* The `DataFrame.nunique()` function returns the number of unique elements.\n",
        "* The `DataFrame.unique()` function returns the unique elements.\n",
        "* The `DataFrame.value_counts()` function returns the unique elements and their frequencies.\n",
        "\n",
        "Let's use these functions to take a closer look at the `Cost Center` variable.\n",
        "\n"
      ],
      "metadata": {
        "id": "QLxO55I_9p6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#number of unique Cost Centers\n",
        "df['Cost Center'].nunique()"
      ],
      "metadata": {
        "id": "4ZAK2nnLPtI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#names of unique Cost Centers\n",
        "df['Cost Center'].unique()"
      ],
      "metadata": {
        "id": "2UyA0jjpPXnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unique Cost Centers and their frequency\n",
        "df['Cost Center'].value_counts()"
      ],
      "metadata": {
        "id": "8n5EMgFZP4GV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As discussed in the Excel portion of the Workshop, outputs like these can be helpful for making sure our data includes all of the Cost Centers that it should.\n",
        "\n"
      ],
      "metadata": {
        "id": "j98flzRE5eS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practice:** The auditee has told us that the only two invoice payment options are check or ACH. Additionally, roughly 30% of the invoices are paid with checks. Using the `Payment Type` variable, check that our data set matches the auditee's statements.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FrV8c1F2XzoI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HOhFMK-cOesA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Data Accuracy**\n",
        "\n",
        "Data accuracy refers to how well the data represents the true values it is intended to measure. To check data accuracy we'll look for duplicates, illogical values, and outliers.\n",
        "\n",
        "**Duplicate Values**\n",
        "\n",
        "First, we'll check for duplicates in the dataset. To identify any duplicates, we can use the `DataFrame.duplicated()` function. This function returns a Boolean `Series` indicating which rows are duplicates (`True`) and which ones are not (`False`). The function has two optional arguments: `subset` and `keep`.\n",
        "* `subset`: If we don't want to base duplicates off every column in the data set, this argument can be used to specify a subset of columns that should be used to identify duplicates.\n",
        "* `keep`: This argument determines which duplicates should be marked (which ones should be assigned a `True` value).\n",
        "  * `'first'`: marks all duplicates as `True` except for the first occurrence\n",
        "  * `'last'`: marks all duplicates as `True` except for the last occurrence\n",
        "  * `False`: marks all duplicates as `True`\n"
      ],
      "metadata": {
        "id": "Hcja5T4m_SDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#identify duplicate rows in df\n",
        "df.duplicated(keep = False)"
      ],
      "metadata": {
        "id": "O5zD08pOqFaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practice:** How many duplicate rows does `df` have?"
      ],
      "metadata": {
        "id": "N3maQz6rjLFN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0OZ8HMbMvojc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In some cases, it is desirable to drop duplicate rows from the `DataFrame`. To do this, we can use the `DataFrame.drop_duplicates()` function. This function has the same optional arguments as `DataFrame.duplicated()`. Using the following choices, the `keep` argument determines which duplicates to retain in the `DataFrame`.  \n",
        "  * `'first'`: drops all duplicates except for the first occurrence\n",
        "  * `'last'`: drops all duplicates except for the last occurrence\n",
        "  * `False`: drops all duplicates\n",
        "\n",
        "For example, the code below would save over `df` with a version of `df` that excludes all duplicates except for the first occurrence.\n",
        "\n",
        "\n",
        "```\n",
        "#drop duplicate rows from df\n",
        "df = df.drop_duplicates(keep = 'first')\n",
        "```\n"
      ],
      "metadata": {
        "id": "FdBCRGN2ql86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned earlier, we can also look for duplicates based on a subset of columns by specifying a list of columns as the `subset` argument in the `DataFrame.duplicated()` function. Let's find which rows have duplicate values in the `Purchase Orders`, `Payment Amount`, and `Due Date` columns.\n",
        "\n"
      ],
      "metadata": {
        "id": "TRkaLJfDsENW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated(subset = ['Purchase Orders', 'Payment Amount', 'Due Date'], keep = False)"
      ],
      "metadata": {
        "id": "nTlWTb57xEZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practice:** How many rows have duplicate values in the `Purchase Orders`, `Payment Amount`, and `Due Date` columns? Display a subset of `df` that only includes the duplicate rows."
      ],
      "metadata": {
        "id": "Ihiocu0WxCQI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dIZf6_3kycZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ogZ_0dLCQ9-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Illogical values**\n",
        "\n",
        "The presence of illogical values can also indicate a problem with data accuracy. For our supplier invoice data, illogical values can be things like negative invoice amounts.\n",
        "\n",
        "Let's add a variable to `df` that indicates if `Invoice Amount` is positive or not.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0hE9z0Ip5cVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#name the variable Invoice_Amt_Pos\n",
        "df['Invoice_Amt_Pos'] = df['Invoice Amount'] >= 0"
      ],
      "metadata": {
        "id": "fKLWC1K768cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use the value_counts function on the Invoice_Amt_Pos variable\n",
        "df['Invoice_Amt_Pos'].value_counts()"
      ],
      "metadata": {
        "id": "-sBQBiQv8oEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practice:** We expect the `Payment Amount` to not exceed the `Invoice Amount`. Add a variable to `df` that indicates if the `Payment Amount` is greater than the `Invoice Amount`. Do any invoices have this issue?"
      ],
      "metadata": {
        "id": "eArHL69z9j-l"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uXkcKxw99waq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practice:** Invoices should be paid on weekdays only (Monday - Friday). Use the variable we created earlier, `Payment Day`, to verify that this is the case.\n"
      ],
      "metadata": {
        "id": "f-rOcbed-A1A"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lycw4uXm6QIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're not sure where to start when checking for illogical values, exploring the data through summaries is a good idea. We can create summaries through the `DataFrame.describe()` and `DataFrame.groupby()` functions.\n",
        "\n",
        "The `DataFrame.describe()` function generates descriptive statistics, but the results of the function will vary based on the data type. Let's look at the descriptive statistics for `Payment Day`.\n",
        "\n"
      ],
      "metadata": {
        "id": "dYIqVA3dcyIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Payment Day'].describe()"
      ],
      "metadata": {
        "id": "0EtWNfBWCnsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practice:** View the descriptive statistics for `Purchase Orders`."
      ],
      "metadata": {
        "id": "ycGN38DxDSBM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYsFOmhGDLNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The descriptive statistics for `Purchase Orders` show that the value of `PO-00128621` appears 149 times. It seems like multiple invoices could be tied to the same value in `Purchase Orders`. To look into this further, we can group the data set by the unique values in `Purchase Orders` through the `DataFrame.groupby()` function. This function takes the variable that we want to group by as the `by` argument."
      ],
      "metadata": {
        "id": "BUbN7Bb7DW-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(by = 'Purchase Orders')"
      ],
      "metadata": {
        "id": "Q2XljeSjIgKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of the `DataFrame.groupby()` function isn't helpful without providing a way to summarize the groups. Let's find the sum of the `Payment Amount` for each unique value of `Purchase Orders`."
      ],
      "metadata": {
        "id": "L2A2MUVcIyX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(by = 'Purchase Orders')['Payment Amount'].sum()"
      ],
      "metadata": {
        "id": "y891sP0ohq9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Through this output, we can see that multiple invoices are tied to the same value in `Purchase Orders`. We can also see that almost all of the values in `Purchase Orders` follow the same format: `PO-00******`. However, the first two do not. It looks like these two are missing the `PO-00` part. This could be due to a data entry error and would be worth confirming with the auditee."
      ],
      "metadata": {
        "id": "dERNZY2CC8Hu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Outliers**\n",
        "\n",
        "The presence of outliers in a data set can also point to a data accuracy problem. Outliers are data points that are significantly different from other data points. To identify outliers, we use what's called a Z-score.\n",
        "\n",
        "The Z-score for a data point tells us the number of standard deviations that point is away from the mean. Formally,\n",
        "\n",
        "$$Z = \\frac{x-\\mu}{\\sigma},$$ where $x$ is the data point, $\\mu$ is the mean, and $\\sigma$ is the standard deviation.\n",
        "\n",
        "Negative Z-scores mean the point is less than the mean and positive Z-scores mean the point is greater than the mean. A common way of identifying outliers is by locating points with a Z-score less than -3 or greater than 3. Practically, this just means that the data point is quite different than the others.\n",
        "\n",
        "\n",
        "Let's see if we have any outliers for the `Invoice Amount` variable. We'll start by calculating the Z-score for each `Invoice Amount`, which requires the mean and standard deviation for `Invoice Amount`. To calculate these we'll use the `DataFrame.mean()` and `DataFrame.std()` functions.\n",
        "\n"
      ],
      "metadata": {
        "id": "hZEzdn-JMehE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the mean Invoice Amount and save it as a variable\n",
        "mean = df['Invoice Amount'].mean()"
      ],
      "metadata": {
        "id": "7eA4uiuFhzCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `DataFrame.std()` function calculates the sample standard deviation by default. However, if we want to calculate the population standard deviation, we need to change the `ddof` argument from its default value of `1` to `0`."
      ],
      "metadata": {
        "id": "7aBPlUzoFTw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the population standard deviation\n",
        "sd = df['Invoice Amount'].std(ddof = 0)"
      ],
      "metadata": {
        "id": "nFl4qcwZF1Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we'll create a variable in `df`, `Inv_Amt_Z`, that contains the Z-score for each invoice amount."
      ],
      "metadata": {
        "id": "ydzB7HCrHOu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the Z-score\n",
        "df['Inv_Amt_Z'] = (df['Invoice Amount'] - mean)/sd"
      ],
      "metadata": {
        "id": "I0pjZK5aHybd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#view Z-scores\n",
        "df['Inv_Amt_Z']"
      ],
      "metadata": {
        "id": "TCJRFm0QIOfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we calculated the Z-scores to check for outliers, it would be helpful if we created a variable that indicated if an `Invoice Amount` was an outlier or not.\n",
        "\n",
        "**Practice:** Add a variable to `df` called `Inv_Amt_Outlier` that is `True` if the `Invoice Amount` is an outlier and `False` if it's not.  Recall that outliers have Z-scores greater than 3 or less than -3. How many outliers are there? *Hint: Use the `abs()` function.*"
      ],
      "metadata": {
        "id": "-TalMUOCIHgT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KVbkDAIgJI08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mZlsbZz_O8G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sampling**\n",
        "\n",
        "If the data set we have is not the primary data source itself, such as a report being pulled from the primary source or things are manually entered into the report by staff, we can also check the accuracy of the data by comparing a sample of our data set to the original source. We can use the `DataFrame.sample()` function to pull a random sample. This function uses the `n` argument to specify how large of a sample we want."
      ],
      "metadata": {
        "id": "5UcwD9Aj323t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pulling a random sample of size 10\n",
        "df.sample(n=10)"
      ],
      "metadata": {
        "id": "s4pC15iT-CWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because this function uses a random number generator to pull samples, the sample will be different every time the code is run. However, the optional `random_state` argument can be used to ensure that the random sample is reproducable. To do this, just set the `random_state` argument equal to an integer of your choice. The choice of integer doesn't matter-- it's simply used to initialize the random number generator. As long as the same integer is used (and the same sample size), anyone who pulls a random sample from `df` will have the same sample returned."
      ],
      "metadata": {
        "id": "qL_YXIRPQVNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#with the random_state argument\n",
        "df.sample(n=10, random_state = 7)"
      ],
      "metadata": {
        "id": "YRbQQrcH_XSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exporting Results**\n",
        "\n",
        "Often, it's helpful to export some results so they can be used outside of Python. For example, we may want to export the random sample we generated or some of the rows where we identified data accuracy issues. pandas also has functions that can be used to write an object to a csv file or Excel file.\n",
        "\n",
        "  * `DataFrame.to_excel()`\n",
        "  * `DataFrame.to_csv()`\n",
        "\n",
        "There are several optional arguments for these functions, so we'll just focus on specifying the file path where we want to save the object. However, our options for the file path are limited because we're using Google Colab. When working in Colab, the simplest place to export an object to is your Google Drive. This requires a bit of setup though, so we won't go into this during the workshop. If you use these functions outside of Colab, you can save objects anywhere on your computer. For example, if we wanted to export the sample we generated earlier, we could use the following code.\n",
        "\n",
        "\n",
        "```\n",
        "#assign the random sample a name\n",
        "sample = df.sample(n=10, random_state = 7)\n",
        "\n",
        "#file path for saving\n",
        "#fill in the string below with a location on your computer\n",
        "file_path = ''\n",
        "\n",
        "#export the sample as an excel file\n",
        "sample.to_excel(file_path)\n",
        "```"
      ],
      "metadata": {
        "id": "Wq-zyy9030Mm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also save multiple objects in separate sheets in the same Excel file; however, the syntax for doing this becomes a little more complicated. The [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html) for the `DataFrame.to_excel()` function includes instructions on how to do this."
      ],
      "metadata": {
        "id": "CwbwP8O1IGuO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Helpful Tips for Running Code**\n",
        "\n",
        "If we have a large number of code blocks, it can be tedious to go through and run every block individually. Instead of doing that, we have a couple of options for running multiple blocks of code.\n",
        "\n",
        "* Runtime → Run all will run all cells in the notebook from top to bottom.\n",
        "\n",
        "* Runtime → Run before will run all cells before the current cell.\n",
        "\n",
        "* Runtime → Run after will run all cells after the current cell.\n",
        "\n",
        "There are also some situations where we might want to stop the code we're running or restart our current session.\n",
        "\n",
        "* Runtime → Restart session will give you a fresh start as if you haven't run any code. Restarting the session can be useful if you're having difficulty debugging your code. However, all of your variables will be gone!\n",
        "\n",
        "* Runtime → Interrupt session will stop whatever code is running. This can be helpful if a code block is taking longer to run than expected and you'd like to stop running it.\n",
        "\n",
        "* Edit → Clear all outputs will erase any outputs you currently have below code blocks.\n",
        "\n"
      ],
      "metadata": {
        "id": "B4c5gBlpshD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Bonus Content**\n",
        "\n",
        "#### **Referencing Items in a List**\n",
        "\n",
        "Because lists are ordered, they are also **indexed**. This means we can access elements within a list by referencing their index.\n",
        "\n",
        "It's important to note here that Python begins indexing with 0. So, the \"first\" item in a list has index 0, not 1. To access an element by its index, we put the index within brackets, `[]`, after the list name."
      ],
      "metadata": {
        "id": "C25BwmLaDnK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define a list that contains state capitals\n",
        "capitals = ['Sacramento', 'Salem', 'Olympia', 'Salt Lake City', 'Denver', 'Sante Fe']\n",
        "\n",
        "#access the first element in the list\n",
        "capitals[0]"
      ],
      "metadata": {
        "id": "dDUTO2f0DrEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use negative indices, which will start at the end of the list instead of the beginning. This can be a convenient way to see the last item in a list if you're not sure how long the list is."
      ],
      "metadata": {
        "id": "ATJBznPDELG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#access the last element in the list\n",
        "capitals[-1]"
      ],
      "metadata": {
        "id": "L5ndbVmYEL0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can access more than just one element at a time by giving a range of indices, such as `[0:2]`. However, in Python, the first number given in the range is inclusive and the last one is not. So, the range `[0:2]`, will provide the elements for indices `[0]` and `[1]`."
      ],
      "metadata": {
        "id": "JIXsIFvKEOp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#access the first two elements in the list\n",
        "capitals[0:2]"
      ],
      "metadata": {
        "id": "ZeJs38K8EQ5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we leave off the starting index for a range, the range will start with the first item in the list by default. Similarly, if we leave off the ending index for a range, the range will end with the last item in the list by default."
      ],
      "metadata": {
        "id": "aAnHPCtREWNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#access all elements with an index of two or larger\n",
        "capitals[2:]"
      ],
      "metadata": {
        "id": "1h-xDCHQEW9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By adding in an additional `:`, we can change the step for the elements we're accessing. The syntax is:\n",
        "\n",
        "```\n",
        "list[start:stop:step]\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G1sr3NV_9QLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#accessing every other element from index 0 up to index 4\n",
        "capitals[0:4:2]"
      ],
      "metadata": {
        "id": "AwPwe7SZIrv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Additional Ways to Subset a DataFrame**\n",
        "\n",
        "We can also subset a `DataFrame` based on row or column numbers like we just did with lists. When specifying row or column numbers, the syntax for subsetting is:\n",
        "\n",
        "```\n",
        "DataFrame.iloc[row number(s), column number(s)]\n",
        "```\n"
      ],
      "metadata": {
        "id": "JbwXrscomxpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#view the entry in the first row and column\n",
        "df.iloc[0,0]"
      ],
      "metadata": {
        "id": "ThIgl4Uh7I0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also specify a range row numbers and column numbers. Recall that the first value in a range is inclusive and the last value is exclusive!"
      ],
      "metadata": {
        "id": "qlszSq36AGos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#view the first two rows and first two columns\n",
        "df.iloc[0:2, 0:2]"
      ],
      "metadata": {
        "id": "dWfM0h_4APLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we only include row numbers in the range, all columns for those rows will be included. Similarly, if we only include column numbers in the range, all rows for those columns will be included."
      ],
      "metadata": {
        "id": "t7Wah4Vs605G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#view the second row in the dataframe\n",
        "df.iloc[2,:]"
      ],
      "metadata": {
        "id": "XwWe8K8evYhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sources**\n",
        "\n",
        "* [W3 Schools Python Tutorial](https://www.w3schools.com/python/)\n",
        "* Gaddis, Tony. (2015). Starting out with Python, 3rd Edition.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Td-JkplTLtns"
      }
    }
  ]
}